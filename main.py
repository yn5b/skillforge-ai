import streamlit as st

st.set_page_config(page_title="Skilvyn Tutor", layout="wide")

SKILLS = ["Prompt Engineering"]

defaults = {
    "chat_history": [],
    "user_info": {},
    "skills": SKILLS,
    "selected_skill": None,
    "skill_level": None,
    "learning_path": [],
    "current_unit": 0,
    "unit_passed": False,
    "stage": "welcome"
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

def llama2_chat(messages, temperature=0.7, max_tokens=256):
    """
    Llama 2 7B API stub: replace with your actual Llama 2 inference endpoint.
    This demo version generates context-aware, direct, conversational responses.
    """
    import json

    # Extract user info if available
    name = st.session_state.user_info.get("name", "")
    email = st.session_state.user_info.get("email", "")
    birth = st.session_state.user_info.get("birth", "")
    skill = st.session_state.selected_skill or "Prompt Engineering"
    level = st.session_state.skill_level or ""

    # Last user message
    user_msgs = [m for m in messages if m["role"] == "user"]
    last_user = user_msgs[-1]["content"] if user_msgs else ""

    # Stage-based AI responses
    stage = st.session_state.stage

    if stage == "welcome":
        return (
            "Welcome to Skilvyn! This is an interactive, AI-powered learning platform. "
            "Everything here is generated by artificial intelligence. What name should I call you?"
        )
    elif stage == "ask_info":
        return f"Nice to meet you, {name}! Could you please provide your email address?"
    elif stage == "choose_skill":
        return "Thank you! Could you share your date of birth? Please use the format YYYY-MM-DD."
    elif stage == "ask_level":
        return (
            "Currently, only the 'Prompt Engineering' skill is available to learn. "
            "More skills will be added soon! Would you like to start learning Prompt Engineering? (yes/no)"
        )
    elif stage == "generate_path":
        return (
            "Great! How would you describe your current experience with Prompt Engineering? "
            "(beginner/intermediate/advanced or a short description)"
        )
    elif stage == "in_unit":
        unit = st.session_state.learning_path[st.session_state.current_unit]
        if last_user.lower().strip() in ["hi", "hello", "hey"]:
            return f"Hello! Let's continue with {unit['title']}. {unit['welcome']}"
        # For demo: pass after 2 user turns, otherwise encourage
        if len(user_msgs) > 1:
            return "Well done! You are ready for the next unit.\n[status:pass]"
        else:
            return "That's a good start! Try to elaborate a bit more.\n[status:stay]"
    elif stage == "path_complete":
        return "ðŸŽ‰ Congratulations! You have completed all units successfully."
    # For generating the learning path JSON
    sys = "\n".join([m["content"] for m in messages if m["role"] == "system"])
    if "Create a plan with 5 units" in sys:
        return json.dumps([
            {"title": "Intro to Prompts", "objective": "Understand what prompts are", "welcome": "Welcome to your first step in prompt engineering!"},
            {"title": "Writing Simple Prompts", "objective": "Learn to write basic prompts", "welcome": "Let's get started with writing simple prompts."},
            {"title": "Prompt Structure", "objective": "Explore structure and clarity", "welcome": "Time to master prompt structure!"},
            {"title": "Advanced Prompting", "objective": "Handle complex prompt scenarios", "welcome": "Level up with advanced prompting techniques."},
            {"title": "Prompt Engineering in Practice", "objective": "Apply your skills", "welcome": "It's time to use your prompt engineering skills in real scenarios!"}
        ])
    return "..."

def show_chat():
    for msg in st.session_state.chat_history:
        if msg["role"] == "assistant":
            st.chat_message("assistant").markdown(msg["content"])
        else:
            st.chat_message("user").markdown(msg["content"])

# ---------- App Flow Logic ----------

if st.session_state.stage == "welcome":
    if not st.session_state.chat_history:
        welcome = llama2_chat([])
        st.session_state.chat_history.append({"role": "assistant", "content": welcome})
    show_chat()
    user_input = st.chat_input("Enter your name or how you'd like to be addressed...")
    if user_input:
        st.session_state.user_info["name"] = user_input.strip()
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        ask = llama2_chat([
            {"role": "user", "content": user_input}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": ask})
        st.session_state.stage = "ask_info"
        st.stop()

elif st.session_state.stage == "ask_info":
    show_chat()
    user_input = st.chat_input("Enter your email address...")
    if user_input:
        st.session_state.user_info["email"] = user_input.strip()
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        ask = llama2_chat([
            {"role": "user", "content": user_input}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": ask})
        st.session_state.stage = "choose_skill"
        st.stop()

elif st.session_state.stage == "choose_skill":
    show_chat()
    user_input = st.chat_input("Enter your date of birth (e.g., 1990-01-01)...")
    if user_input:
        st.session_state.user_info["birth"] = user_input.strip()
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        ask = llama2_chat([
            {"role": "user", "content": user_input}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": ask})
        st.session_state.stage = "ask_level"
        st.stop()

elif st.session_state.stage == "ask_level":
    show_chat()
    user_input = st.chat_input("Would you like to learn Prompt Engineering? (yes/no)...")
    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        if user_input.strip().lower() == "yes":
            st.session_state.selected_skill = "Prompt Engineering"
            ask = llama2_chat([
                {"role": "user", "content": user_input}
            ])
            st.session_state.chat_history.append({"role": "assistant", "content": ask})
            st.session_state.stage = "generate_path"
            st.stop()
        else:
            sorry = "Thank you for your interest! You can return later when more skills are added."
            st.session_state.chat_history.append({"role": "assistant", "content": sorry})
            st.session_state.stage = "welcome"
            st.stop()

elif st.session_state.stage == "generate_path":
    show_chat()
    user_input = st.chat_input("Describe your current experience...")
    if user_input:
        st.session_state.skill_level = user_input.strip()
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        # Generate learning path
        prompt = (
            f"You are an AI learning assistant for a student named {st.session_state.user_info['name']} who wants to learn Prompt Engineering. "
            f"Their experience: {st.session_state.skill_level}. Create a plan with 5 units, each with a short title, a learning objective, and a welcome message for the unit. "
            "Return the list as JSON with objects containing: title, objective, welcome."
        )
        plan = llama2_chat([{"role": "system", "content": prompt}])
        import json
        try:
            learning_path = json.loads(plan)
            st.session_state.learning_path = learning_path
            st.session_state.current_unit = 0
            st.session_state.stage = "in_unit"
            # Welcome message for first unit
            unit = learning_path[0]
            msg = f"Let's start your learning journey!\n\n**{unit['title']}**\n{unit['welcome']}"
            st.session_state.chat_history.append({"role": "assistant", "content": msg})
            st.stop()
        except Exception:
            st.session_state.chat_history.append({"role": "assistant", "content": "An error occurred while generating your learning path. Please try again."})
            st.session_state.stage = "welcome"
            st.stop()

elif st.session_state.stage == "in_unit":
    unit = st.session_state.learning_path[st.session_state.current_unit]
    show_chat()
    user_input = st.chat_input("Ask or answer via chat...")
    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        # Tutor: pass/stay based on answer
        reply = llama2_chat([
            {"role": "user", "content": user_input}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": reply})
        if "[status:pass]" in reply:
            if st.session_state.current_unit + 1 < len(st.session_state.learning_path):
                st.session_state.current_unit += 1
                next_unit = st.session_state.learning_path[st.session_state.current_unit]
                msg = f"Great! Moving to the next unit:\n\n**{next_unit['title']}**\n{next_unit['welcome']}"
                st.session_state.chat_history.append({"role": "assistant", "content": msg})
                st.stop()
            else:
                st.session_state.stage = "path_complete"
                complete_msg = llama2_chat([])
                st.session_state.chat_history.append({"role": "assistant", "content": complete_msg})
                st.stop()
        elif "[status:stay]" in reply:
            encourage = "Keep going! Practice a bit more in this unit, and you'll be ready for the next one."
            st.session_state.chat_history.append({"role": "assistant", "content": encourage})
            st.stop()

elif st.session_state.stage == "path_complete":
    show_chat()
    st.success("You have completed the program! You can start over or review your units.")
    if st.button("Start Over"):
        for k in ("chat_history", "user_info", "selected_skill", "skill_level", "learning_path", "current_unit", "stage"):
            st.session_state[k] = defaults[k]
        st.stop()
