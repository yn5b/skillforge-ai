import streamlit as st

st.set_page_config(page_title="Skilvyn Tutor", layout="wide")

SKILLS = ["Prompt Engineering"]

defaults = {
    "chat_history": [],
    "user_info": {},
    "skills": SKILLS,
    "selected_skill": None,
    "skill_level": None,
    "learning_path": [],
    "current_unit": 0,
    "unit_passed": False,
    "stage": "welcome"
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# --------- Llama 2 7B API Wrapper (should reply directly, not echo prompt) ---------
def llama2_chat(messages, temperature=0.7, max_tokens=256):
    """
    Replace this stub with your Llama 2 7B API call.
    This version demonstrates how to send the full chat context and get a direct reply.
    """
    # Example with a hypothetical REST API:
    # response = requests.post("YOUR_LLAMA2_API_ENDPOINT", json={"messages": messages, ...})
    # return response.json()["reply"]

    # -------------- LLAMA 2 7B DUMMY LOGIC FOR DEMO ---------------
    # This block simulates actual completion for demo, replace with real inference in production.
    last_user = ""
    for msg in reversed(messages):
        if msg["role"] == "user":
            last_user = msg["content"]
            break
    sys_prompts = [m["content"] for m in messages if m["role"] == "system"]
    if messages and "welcome" in st.session_state.stage:
        return ("Welcome to Skilvyn! This is an interactive AI-powered learning platform. "
                "Everything you see here is generated by artificial intelligence. "
                "What name would you like me to call you?")
    if messages and "Politely ask them for their email address." in "".join(sys_prompts):
        return f"Nice to meet you, {last_user}! Could you please tell me your email address?"
    if messages and "Ask the user for their date of birth" in "".join(sys_prompts):
        return "Thank you! Could you share your date of birth? (Format: YYYY-MM-DD)"
    if messages and "Tell the user that currently only" in "".join(sys_prompts):
        return ("Currently, only the 'Prompt Engineering' skill is available to learn. "
                "More skills will be added soon! Would you like to start learning Prompt Engineering?")
    if messages and "Ask the user to briefly describe their current experience level" in "".join(sys_prompts):
        return "Great! How would you describe your current experience with Prompt Engineering (beginner/intermediate/advanced or a short description)?"
    if messages and "Thank the user and let them know they can return later" in "".join(sys_prompts):
        return "Thank you for your interest! You can return later when more skills are added."
    if messages and "Welcome the user and inform them they are starting with the first unit" in "".join(sys_prompts):
        return "Let's start your learning journey! Here is your first unit. Good luck!"
    if messages and "Encourage the user to keep working on this unit" in "".join(sys_prompts):
        return "Keep going! Practice a bit more in this unit, and you'll be ready for the next one."
    # Learning path JSON generation
    if messages and "Create a plan with 5 units" in "".join(sys_prompts):
        import json
        return json.dumps([
            {"title": "Intro to Prompts", "objective": "Understand what prompts are", "welcome": "Welcome to your first step in prompt engineering!"},
            {"title": "Writing Simple Prompts", "objective": "Learn to write basic prompts", "welcome": "Let's get started with writing simple prompts."},
            {"title": "Prompt Structure", "objective": "Explore structure and clarity", "welcome": "Time to master prompt structure!"},
            {"title": "Advanced Prompting", "objective": "Handle complex prompt scenarios", "welcome": "Level up with advanced prompting techniques."},
            {"title": "Prompt Engineering in Practice", "objective": "Apply your skills", "welcome": "It's time to use your prompt engineering skills in real scenarios!"}
        ])
    # Tutor logic (pass/stay)
    if messages and "Evaluate the student's answer" in "".join(sys_prompts):
        # For demo, always pass after 2 user turns, else stay
        user_msgs = [m for m in messages if m["role"] == "user"]
        if len(user_msgs) > 1:
            return "Well done! You are ready for the next unit.\n[status:pass]"
        else:
            return "Great start! Try to elaborate a bit more.\n[status:stay]"
    return "..."

def assistant_reply(user_input=None):
    history = st.session_state.chat_history.copy()
    if user_input:
        history.append({"role": "user", "content": user_input})
    reply = llama2_chat(history)
    history.append({"role": "assistant", "content": reply})
    st.session_state.chat_history = history
    return reply

def show_chat():
    for msg in st.session_state.chat_history:
        if msg["role"] == "assistant":
            st.chat_message("assistant").markdown(msg["content"])
        else:
            st.chat_message("user").markdown(msg["content"])

# --------- App Flow Logic ---------

if st.session_state.stage == "welcome":
    if not st.session_state.chat_history:
        welcome = llama2_chat([
            {"role": "system", "content": "You are a friendly educational chatbot assistant. Speak English. Explain everything to the user, and clarify that all content is AI-generated."},
            {"role": "user", "content": "Welcome the user to Skilvyn, explain it is an interactive AI-powered learning platform. Make it clear that all content in this app is generated by AI."}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": welcome})
    show_chat()
    user_input = st.chat_input("Enter your name or how you'd like to be addressed...")
    if user_input:
        st.session_state.user_info["name"] = user_input.strip()
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        ask = llama2_chat([
            {"role": "system", "content": "You are a friendly educational chatbot assistant. Speak English."},
            {"role": "user", "content": f"The user said their name is {user_input}. Politely ask them for their email address."}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": ask})
        st.session_state.stage = "ask_info"
        st.stop()

elif st.session_state.stage == "ask_info":
    show_chat()
    user_input = st.chat_input("Enter your email address...")
    if user_input:
        st.session_state.user_info["email"] = user_input.strip()
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        ask = llama2_chat([
            {"role": "system", "content": "You are a friendly educational chatbot assistant. Speak English."},
            {"role": "user", "content": "Ask the user for their date of birth (format: YYYY-MM-DD) in a concise and polite way."}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": ask})
        st.session_state.stage = "choose_skill"
        st.stop()

elif st.session_state.stage == "choose_skill":
    show_chat()
    user_input = st.chat_input("Enter your date of birth (e.g., 1990-01-01)...")
    if user_input:
        st.session_state.user_info["birth"] = user_input.strip()
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        skills_message = llama2_chat([
            {"role": "system", "content": "You are a friendly educational chatbot assistant. Speak English."},
            {"role": "user", "content": "Tell the user that currently only 'Prompt Engineering' is available to learn, and more skills will be added soon. Ask them to confirm if they want to start learning Prompt Engineering."}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": skills_message})
        st.session_state.stage = "ask_level"
        st.stop()

elif st.session_state.stage == "ask_level":
    show_chat()
    user_input = st.chat_input("Would you like to learn Prompt Engineering? (yes/no)...")
    if user_input and "yes" in user_input.strip().lower():
        st.session_state.selected_skill = "Prompt Engineering"
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        ask = llama2_chat([
            {"role": "system", "content": "You are a friendly educational chatbot assistant. Speak English."},
            {"role": "user", "content": "Ask the user to briefly describe their current experience level in Prompt Engineering (beginner/intermediate/advanced or a short sentence about themselves)."}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": ask})
        st.session_state.stage = "generate_path"
        st.stop()
    elif user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        sorry = llama2_chat([
            {"role": "system", "content": "You are a friendly educational chatbot assistant. Speak English."},
            {"role": "user", "content": "Thank the user and let them know they can return later when more skills are added."}
        ])
        st.session_state.chat_history.append({"role": "assistant", "content": sorry})
        st.stop()

elif st.session_state.stage == "generate_path":
    show_chat()
    user_input = st.chat_input("Describe your current experience...")
    if user_input:
        st.session_state.skill_level = user_input.strip()
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        prompt = (
            f"You are an AI learning assistant for a student named {st.session_state.user_info['name']} who wants to learn Prompt Engineering. "
            f"Their experience: {st.session_state.skill_level}. Create a plan with 5 units, each with a short title, a learning objective, and a welcome message for the unit. "
            "Return the list as JSON with objects containing: title, objective, welcome."
        )
        plan = llama2_chat([{"role": "system", "content": prompt}], temperature=0.5, max_tokens=512)
        import json
        try:
            learning_path = json.loads(plan)
            st.session_state.learning_path = learning_path
            st.session_state.current_unit = 0
            st.session_state.stage = "in_unit"
            msg = llama2_chat([
                {"role": "system", "content": "You are a friendly educational chatbot assistant. Speak English."},
                {"role": "user", "content": f"Welcome the user and inform them they are starting with the first unit: {learning_path[0]['title']}. Show the unit's welcome message."}
            ])
            msg += f"\n\n{learning_path[0]['welcome']}"
            st.session_state.chat_history.append({"role": "assistant", "content": msg})
            st.stop()
        except Exception:
            st.session_state.chat_history.append({"role": "assistant", "content": "An error occurred while generating your learning path. Please try again."})
            st.stop()

elif st.session_state.stage == "in_unit":
    unit = st.session_state.learning_path[st.session_state.current_unit]
    show_chat()
    user_input = st.chat_input("Ask or answer via chat...")
    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        tutor_prompt = [
            {"role": "system", "content": (
                f"You are a smart tutor. The unit: {unit['title']}. Unit objective: {unit['objective']}."
                " Evaluate the student's answer and respond. At the end, on a separate line, add: [status:pass] if ready for the next unit, or [status:stay] if not ready."
            )},
        ] + st.session_state.chat_history[-6:]
        reply = llama2_chat(tutor_prompt)
        st.session_state.chat_history.append({"role": "assistant", "content": reply})
        if "[status:pass]" in reply:
            if st.session_state.current_unit + 1 < len(st.session_state.learning_path):
                st.session_state.current_unit += 1
                next_unit = st.session_state.learning_path[st.session_state.current_unit]
                msg = llama2_chat([
                    {"role": "system", "content": "You are a friendly educational chatbot assistant. Speak English."},
                    {"role": "user", "content": f"Let the user know they've moved to the next unit titled: {next_unit['title']}. Show the unit's welcome message."}
                ])
                msg += f"\n\n{next_unit['welcome']}"
                st.session_state.chat_history.append({"role": "assistant", "content": msg})
                st.stop()
            else:
                st.session_state.stage = "path_complete"
                st.session_state.chat_history.append({"role": "assistant", "content": "🎉 Congratulations! You have completed all units successfully."})
                st.stop()
        elif "[status:stay]" in reply:
            encourage = llama2_chat([
                {"role": "system", "content": "You are a friendly educational chatbot assistant. Speak English."},
                {"role": "user", "content": "Encourage the user to keep working on this unit until they're ready to move on."}
            ])
            st.session_state.chat_history.append({"role": "assistant", "content": encourage})
            st.stop()

elif st.session_state.stage == "path_complete":
    show_chat()
    st.success("You have completed the program! You can start over or review your units.")
    if st.button("Start Over"):
        for k in ("chat_history", "user_info", "selected_skill", "skill_level", "learning_path", "current_unit", "stage"):
            st.session_state[k] = defaults[k]
        st.stop()
